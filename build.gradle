plugins { 
    id 'java'

    // Gradle Properties plugin
    id 'net.saliman.properties' version '1.4.6'

    // Data Hub plugin
    id 'com.marklogic.ml-data-hub' version '5.2.2'

    id "io.github.http-builder-ng.http-plugin" version "0.1.1"
}

repositories {
    jcenter()
    maven { url 'https://dl.bintray.com/marklogic-community/Maven/' }
	maven { url "http://developer.marklogic.com/maven2/" }
}

configurations {
    mlcp {
        // stop Gradle from complaining about "SLF4J: Class path contains multiple SLF4J bindings."
        exclude group: 'ch.qos.logback', module: 'logback-classic'
        exclude group: 'org.apache.avro', module: 'avro-tools'
    }
}

dependencies {
    mlcp "com.marklogic:mlcp:10.0.4"
    mlcp files("mlcp/conf")
    mlcp files("mlcp/lib")
}

ext {
    MLCP_LOGFILE = "./mlcp.log"
}

gradle.taskGraph.whenReady { taskGraph ->
    def tasks = taskGraph.getAllTasks()
    tasks.findAll { task ->
        // these are the allowed tasks
        def allowedTasks = [
            'mlDeleteCollections'
        ]
        if (((task.name.startsWith("ml") && !(task.name.startsWith("mlcp"))) || task.name.startsWith("hub") ) && 
                task.name in allowedTasks == false )  {
            task.enabled=false
            println("This project does not allow you to run task [" + task.name + "] ")
        }
    }
}

task loadConfiguration(type: com.marklogic.gradle.task.MlcpTask) {
    group 'Configuration'
    classpath = configurations.mlcp
    command = "IMPORT"
    username=mlUsername
    password=mlPassword
    port = mlStagingPort.toInteger()
    input_file_path = sccssConfigurationLocation
    input_file_pattern=".*\\.json"
    output_uri_replace = ".*data,''"
    output_permissions = "data-hub-operator,read,data-hub-operator,update"
    output_collections = "configuration,configuration/project"
}

class DhfOntologyMlcpTask extends com.marklogic.gradle.task.MlcpTask {
   DhfOntologyMlcpTask() {
        classpath = project.configurations.mlcp
        command = "IMPORT"
        port = project.property("mlFinalPort").toInteger()
        input_file_path = project.property('sccssOntologyLocation')
        input_file_type = "RDF"
        output_permissions = "data-hub-operator,read,data-hub-operator,update"
   } 
}

project.properties.each{ key, value ->
    if (key.startsWith("mlcpOntology") && value) {
        def seq = key.tokenize("-")  
        def graph = seq[1]
        task "mlcpOntologyDelete-${graph}"(type: com.marklogic.gradle.task.MarkLogicTask) {
            group = "MLCP OntologyDelete"
            doFirst {
                println "deleting triple graph http://sensingclues.nl/${graph}"
            }
            doLast {
                try {
                    getManageClient().delete("/v1/graphs?database=${mlFinalDbName}&graph=http://sensingclues.nl/${graph}")
                } catch (e) {
                    println "Ontology in graph ${graph} was not loaded..."
                }
            }
        }
        task "mlcpOntologyLoad-${graph}"(type: DhfOntologyMlcpTask) {
            group = "MLCP OntologyLoad"
            input_file_pattern = value
            output_collections = "http://sensingclues.nl/${graph}"
        }
    }
}

task deleteOntology() {
    dependsOn {
        tasks.findAll { task -> "MLCP OntologyDelete".equals(task.group) }
    }   
}

task loadOntology(dependsOn: ['deleteOntology']) {
    dependsOn {
        tasks.findAll { task -> "MLCP OntologyLoad".equals(task.group) }
    }   
}

task deployProject(type: io.github.httpbuilderng.http.HttpTask){
    group 'Configuration Project'
    config {
        request.uri = 'http://' + mlHost + ":" + mlStagingPort.toInteger()
        request.contentType = 'application/json'
        request.auth.digest(mlUsername, mlPassword)
        request.body = [name: sccssProject, description: sccssProjectDescription]
    }
    post {
        request.uri.path = '/v1/resources/project'
        response.success {  groovyx.net.http.FromServer fs, Object body ->
            println "Success: ${fs.statusCode}, Response is: ${body}"
        }
        response.failure { groovyx.net.http.FromServer fs, Object body ->
            println "Failure: ${fs.statusCode}, Response is: ${body}"
        }
    }
}

class DhfMlcpTask extends com.marklogic.gradle.task.MlcpTask {
    DhfMlcpTask() {
        classpath = project.configurations.mlcp
        command = "IMPORT"
        port = project.property("mlStagingPort").toInteger()
        username = project.property("mlUsername")
        password = project.property("mlPassword")
        output_permissions = "data-hub-operator,read,data-hub-operator,update"
        transform_module = "/data-hub/5/transforms/mlcp-flow-transform.sjs"
        batch_size=project.property("mlcpBatchSize").toInteger()
        thread_count=project.property("mlcpThreadCount").toInteger()
    }
}

// dynamically creation of loading Observations
project.properties.each { key, value ->
    if (key.startsWith("mlcp-Observation") && value) {
        def seq = key.tokenize("-")  
        def entityType = seq[1]
        def recordType = seq[2].toLowerCase()
        def separator = value.substring(0, value.lastIndexOf(","))
        def delimiter = separator + "-delimit.opt"
        def path = value.substring(value.lastIndexOf(",")+ 1)
        task "mlcp-${entityType}-${recordType}"(type: DhfMlcpTask) {
            group = "MLCP Observation"
            input_file_path = path
            input_file_type = "delimited_text"
            output_collections = "${entityType},sccss-ingest,type/${recordType}"
            document_type = "json"
            generate_uri = true
            transform_param = 'step=1,flow-name=ingestCSVData,options={' +
            '  \"generate_uri\" : true,' +
            '  \"headers\" : {' +
            '    \"sources\" : [ {' +
            '      \"name\" : \"ingestCSVData\"' +
            '    } ],' +
            '    \"projectName\" : \"' +sccssProject + '\",' +
            '    \"projectId\" : \"' +sccssProjectId + '\",' +
            '    \"entityName\" : \"' + entityType + '\",' +
            '    \"entityType\" : \"' + recordType + '\"' +
            '  },' +
            '  \"outputFormat\" : \"json\"' +
            '}'
            args = ["-options_file", delimiter]
        }
    }
}

task mlcpAllObservations {
    dependsOn {
        tasks.findAll { task -> "MLCP Observation".equals(task.group) }
    }
}

// dynamically creation of Media
project.properties.each { key, value ->
    if (key.startsWith("mlcp-Media") && value) {
        def seq = key.tokenize("-")  
        def entityType = seq[1]
        def recordType = seq[2].toLowerCase()
        task "mlcp-${entityType}-${recordType}"(type: DhfMlcpTask) {
            group 'MLCP Media'
            input_file_path = value
            input_file_type = "documents"
            input_file_pattern = ".*\\.(avi|AVI|JPG|jpg|jpeg)"
            document_type = "binary"
            output_uri_replace = ".*${value},''"
            output_uri_prefix = "/${entityType}/${sccssProjectId}"
            output_collections = "${entityType},sccss-binaries"
            transform_param = 'step=1,flow-name=IngestBinaries,options={' +
            '  \"generate_uri\" : true,' +
            '  \"headers\" : {' +
            '    \"sources\" : [ {' +
            '      \"name\" : \"IngestBinaries\"' +
            '    } ],' +
            '    \"projectName\" : \"' +sccssProject + '\",' +
            '    \"projectId\" : \"' +sccssProjectId + '\",' +
            '    \"entityName\" : \"' + entityType + '\"' +
            '  },' +
            '  \"outputFormat\" : \"json\"' +
            '}'
        }
    }
}

task mlcpAllMedia {
    dependsOn {
        tasks.findAll { task -> "MLCP Media".equals(task.group) }
    }
}

project.properties.each { key, value ->
    if (key.startsWith("mlcp-GeoFeature") && value) {
        def seq = key.tokenize("-")  
        def entityType = seq[1]
        def recordType = seq[2]
        if (recordType == 'Track') {
            task "mlcp-${entityType}-${recordType}"(type: DhfMlcpTask) {
                group 'MLCP GeoFeature'
                input_file_path = value
                input_file_type = "documents"
                input_file_pattern = ".*\\.LOG"
                document_type = "text"
                output_uri_replace = ".*${value},'',\\.LOG,'.json'"
                output_uri_prefix = "/${entityType}/${sccssProjectId}/${recordType}"
                output_collections = "${entityType},sccss-tracks,type/${recordType}"
                transform_param = 'step=1,flow-name=IngestTracks,options={' +
                '  \"headers\" : {' +
                '    \"sources\" : [ {' +
                '      \"name\" : \"IngestTracks\"' +
                '    } ],' +
                '    \"projectName\" : \"' +sccssProject + '\",' +
                '    \"projectId\" : \"' +sccssProjectId + '\",' +
                '    \"entityName\" : \"' + entityType + '\",' +
                '    \"entityType\" : \"' + recordType + '\"' +
                '  }' +
                '}'
            }
        } else if (recordType == 'Geojson') {
            task "mlcp-${entityType}-${recordType}"(type: DhfMlcpTask) {
                group 'MLCP GeoFeature'
                input_file_path = value
                input_file_pattern = ".*\\.geojson"
                input_file_type = "documents"
                document_type = "text"
                generate_uri = true
                output_collections = "${entityType},sccss-geojson,type/${recordType}"
                transform_param = 'step=1,flow-name=IngestGeojson,options={' +
                '  \"generate_uri\" : true,' +
                '  \"headers\" : {' +
                '    \"sources\" : [ {' +
                '      \"name\" : \"IngestGeoJson\"' +
                '    } ],' +
                '    \"projectName\" : \"' +sccssProject + '\",' +
                '    \"projectId\" : \"' +sccssProjectId + '\",' +
                '    \"entityName\" : \"' + entityType + '\",' +
                '    \"entityType\" : \"' + recordType + '\"' +
                '  }' +
                '}'
            }
        }
    }
}
task mlcpAllGeoFeatures {
    dependsOn {
        tasks.findAll { task -> "MLCP GeoFeature".equals(task.group) }
    }
}

task runFlow(type: JavaExec) {
   classpath = files('marklogic-data-hub-'+mlDHFVersion+'-client.jar')
   main = 'com.marklogic.hub.cli.client.Main'
   args 'runFlow'
   args '-host', project.property('mlHost')
   args '-username', project.property('mlUsername')
   args '-password', project.property('mlPassword')
   args '-flowName', flowName
   args '-steps', step
}
